{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY'] = \"\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder, SystemMessagePromptTemplate, HumanMessagePromptTemplate, PromptTemplate\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pankaj rawat\\IdeaProjects\\sarvam-assignment\n"
     ]
    }
   ],
   "source": [
    "\n",
    "current_directory = os.getcwd()\n",
    "file_path = (\n",
    "    os.path.join(current_directory, \"assignment_1/data\", \"iesc111.pdf\")\n",
    ")\n",
    "\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vector_store = FAISS.from_documents(pages, GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\"))\n",
    "retriever = vector_store.as_retriever(k = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are a helpful assistant.\n",
    "    Use the retriever_tool for context if asked question on topic sound. Say don't know the answer if you can't find the answer. \n",
    "    Also you can use youtube video links finder tool. So when asked about videos or links about topic, \n",
    "    use the tool and return the links as well. You can use both the tools if required.\"\"\"\n",
    "\n",
    "messages = [SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=template), additional_kwargs={}),\n",
    "   MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
    "   HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
    "   MessagesPlaceholder(variable_name='agent_scratchpad')]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "        messages\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "# this tool takes a query and outputs the relevant documents in string format\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"sound_search\",\n",
    "    \"Search for information about 'sound'. For any questions about 'sound', you must use this tool!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# youtube tool\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "\n",
    "# Set your YouTube Data API key\n",
    "YOUTUBE_API_KEY = \"AIzaSyAFmHjkY8q1c-BFC8_d9645GtigoIZAJ3E\"  # Ensure you set this in your environment variables\n",
    "\n",
    "@tool\n",
    "def search_youtube(query: str):\n",
    "    \"\"\"Search YouTube for videos related to the query asked.\"\"\"\n",
    "    url = f\"https://www.googleapis.com/youtube/v3/search?part=snippet&maxResults=5&q={query}&key={YOUTUBE_API_KEY}\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        results = response.json()\n",
    "        video_links = []\n",
    "        for item in results.get(\"items\", []):\n",
    "            video_id = item[\"id\"].get(\"videoId\")\n",
    "            if video_id:\n",
    "                video_links.append(f\"https://www.youtube.com/watch?v={video_id}\")\n",
    "        return video_links\n",
    "    else:\n",
    "        return [\"Error retrieving videos. Please try again later.\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Key 'title' is not supported in schema, ignoring\n",
      "Key 'title' is not supported in schema, ignoring\n",
      "Key 'title' is not supported in schema, ignoring\n",
      "Key 'title' is not supported in schema, ignoring\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "tools = [retriever_tool, search_youtube]\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mHello! How can I help you today? ðŸ˜Š \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hello', 'output': 'Hello! How can I help you today? ðŸ˜Š \\n'}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "agent_executor.invoke({\"input\": \"hello\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "chat_history = \"\"\n",
    "\n",
    "while True:\n",
    "    question = input(\"ask a question on topic 'sound'. Input 'stop' to stop the chat\")\n",
    "\n",
    "    if question == 'stop':\n",
    "        break\n",
    "\n",
    "    rag_chain = (\n",
    "        {\"context\": itemgetter(\"question\") | retriever | format_docs, \"question\": itemgetter(\"question\"), \"chat_history\": itemgetter(\"chat_history\")}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    answer = rag_chain.invoke({\"question\": question, \"chat_history\": chat_history})\n",
    "\n",
    "    chat_history = chat_history + f\"Question: {question}\\nAnswer: {answer}\\n\"\n",
    "    print(chat_history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"detail\":\"Missing boundary in multipart.\"}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.sarvam.ai/speech-to-text\"\n",
    "\n",
    "payload = \"-----011000010111000001101001\\r\\nContent-Disposition: form-data; name=\\\"language_code\\\"\\r\\n\\r\\nhi-IN\\r\\n-----011000010111000001101001\\r\\nContent-Disposition: form-data; name=\\\"model\\\"\\r\\n\\r\\nsaarika:v1\\r\\n-----011000010111000001101001--\\r\\n\\r\\n\"\n",
    "headers = {\"Content-Type\": \"multipart/form-data\"}\n",
    "\n",
    "response = requests.request(\"POST\", url, data=payload, headers=headers)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 422\n",
      "Response Body: {'detail': [{'type': 'string_type', 'loc': ['body', 'chat_history'], 'msg': 'Input should be a valid string', 'input': []}]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Define the URL and the query message\n",
    "url = \"http://127.0.0.1:8000/rag\"\n",
    "data = {\"query\": \"what was my previous question\", \"chat_history\":[]}\n",
    "\n",
    "# Make the POST request\n",
    "response = requests.post(url, json=data)\n",
    "\n",
    "# Print the response from the server\n",
    "print(\"Status Code:\", response.status_code)\n",
    "print(\"Response Body:\", response.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sarvam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
